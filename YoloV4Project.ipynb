{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YoloV4Project.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gpvprasad/Project2022/blob/main/YoloV4Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxS_ayfsIonI",
        "outputId": "25f2db70-624e-46aa-bbdd-38b1485a8e4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'objectidentificationvideo'...\n",
            "remote: Enumerating objects: 167, done.\u001b[K\n",
            "remote: Counting objects: 100% (167/167), done.\u001b[K\n",
            "remote: Compressing objects: 100% (127/127), done.\u001b[K\n",
            "remote: Total 167 (delta 68), reused 90 (delta 27), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (167/167), 5.11 MiB | 11.81 MiB/s, done.\n",
            "Resolving deltas: 100% (68/68), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/prasadmlexpert/objectidentificationvideo.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/objectidentificationvideo/Reference/PyTorch_YOLOv4/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suNKsX1PJe8t",
        "outputId": "407cc205-d435-46ef-bb13-4e4b3adfb279"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/objectidentificationvideo/Reference/PyTorch_YOLOv4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QszrEsC7XQ0V",
        "outputId": "3fdc75d7-8836-4907-a0a4-88d509a1a9ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting numpy==1.17\n",
            "  Downloading numpy-1.17.0-cp37-cp37m-manylinux1_x86_64.whl (20.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.3 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (4.1.2.30)\n",
            "Collecting torch==1.6\n",
            "  Downloading torch-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (748.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 748.8 MB 18 kB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (0.12.0+cu113)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (3.2.2)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (2.0.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (4.64.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (7.1.2)\n",
            "Requirement already satisfied: tensorboard>=1.14 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (2.8.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6->-r requirements.txt (line 3)) (0.16.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->-r requirements.txt (line 9)) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->-r requirements.txt (line 9)) (3.3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->-r requirements.txt (line 9)) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->-r requirements.txt (line 9)) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->-r requirements.txt (line 9)) (0.4.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->-r requirements.txt (line 9)) (57.4.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->-r requirements.txt (line 9)) (1.1.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->-r requirements.txt (line 9)) (0.6.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->-r requirements.txt (line 9)) (3.17.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->-r requirements.txt (line 9)) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->-r requirements.txt (line 9)) (0.37.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->-r requirements.txt (line 9)) (1.46.3)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->-r requirements.txt (line 9)) (4.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->-r requirements.txt (line 9)) (1.15.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->-r requirements.txt (line 9)) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->-r requirements.txt (line 9)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->-r requirements.txt (line 9)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=1.14->-r requirements.txt (line 9)) (4.11.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=1.14->-r requirements.txt (line 9)) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=1.14->-r requirements.txt (line 9)) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=1.14->-r requirements.txt (line 9)) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->-r requirements.txt (line 9)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->-r requirements.txt (line 9)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->-r requirements.txt (line 9)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->-r requirements.txt (line 9)) (2022.6.15)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->-r requirements.txt (line 9)) (3.2.0)\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.13.0-cp37-cp37m-manylinux1_x86_64.whl (19.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.1 MB 983 kB/s \n",
            "\u001b[?25h  Downloading torchvision-0.12.0-cp37-cp37m-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.0 MB 1.3 MB/s \n",
            "\u001b[?25h  Downloading torchvision-0.11.3-cp37-cp37m-manylinux1_x86_64.whl (23.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.2 MB 1.3 MB/s \n",
            "\u001b[?25h  Downloading torchvision-0.11.2-cp37-cp37m-manylinux1_x86_64.whl (23.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.3 MB 1.3 MB/s \n",
            "\u001b[?25h  Downloading torchvision-0.11.1-cp37-cp37m-manylinux1_x86_64.whl (23.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.3 MB 1.3 MB/s \n",
            "\u001b[?25h  Downloading torchvision-0.10.1-cp37-cp37m-manylinux1_x86_64.whl (22.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.1 MB 1.3 MB/s \n",
            "\u001b[?25h  Downloading torchvision-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (22.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.1 MB 1.2 MB/s \n",
            "\u001b[?25h  Downloading torchvision-0.9.1-cp37-cp37m-manylinux1_x86_64.whl (17.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.4 MB 741 kB/s \n",
            "\u001b[?25h  Downloading torchvision-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (17.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3 MB 169 kB/s \n",
            "\u001b[?25h  Downloading torchvision-0.8.2-cp37-cp37m-manylinux1_x86_64.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 20 kB/s \n",
            "\u001b[?25h  Downloading torchvision-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (12.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.7 MB 29.5 MB/s \n",
            "\u001b[?25h  Downloading torchvision-0.8.0-cp37-cp37m-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.8 MB 22.0 MB/s \n",
            "\u001b[?25h  Downloading torchvision-0.7.0-cp37-cp37m-manylinux1_x86_64.whl (5.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 22.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 5)) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 5)) (1.4.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 5)) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 5)) (0.11.0)\n",
            "Installing collected packages: numpy, torch, torchvision\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.11.0+cu113\n",
            "    Uninstalling torch-1.11.0+cu113:\n",
            "      Successfully uninstalled torch-1.11.0+cu113\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.12.0+cu113\n",
            "    Uninstalling torchvision-0.12.0+cu113:\n",
            "      Successfully uninstalled torchvision-0.12.0+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray 0.20.2 requires numpy>=1.18, but you have numpy 1.17.0 which is incompatible.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.17.0 which is incompatible.\n",
            "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.6.0 which is incompatible.\n",
            "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.6.0 which is incompatible.\n",
            "tensorflow 2.8.2+zzzcolab20220527125636 requires numpy>=1.20, but you have numpy 1.17.0 which is incompatible.\n",
            "tables 3.7.0 requires numpy>=1.19.0, but you have numpy 1.17.0 which is incompatible.\n",
            "pywavelets 1.3.0 requires numpy>=1.17.3, but you have numpy 1.17.0 which is incompatible.\n",
            "pandas 1.3.5 requires numpy>=1.17.3; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\", but you have numpy 1.17.0 which is incompatible.\n",
            "kapre 0.3.7 requires numpy>=1.18.5, but you have numpy 1.17.0 which is incompatible.\n",
            "jaxlib 0.3.7+cuda11.cudnn805 requires numpy>=1.19, but you have numpy 1.17.0 which is incompatible.\n",
            "jax 0.3.8 requires numpy>=1.19, but you have numpy 1.17.0 which is incompatible.\n",
            "fastai 2.6.3 requires torch<1.12,>=1.7.0, but you have torch 1.6.0 which is incompatible.\n",
            "fastai 2.6.3 requires torchvision>=0.8.2, but you have torchvision 0.7.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.17.0 torch-1.6.0 torchvision-0.7.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "id": "wt39bl9IpQIG",
        "outputId": "7c7e5f58-eeb7-4edb-aa53-93db319ce72e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/bdd100k/bdd100k.git"
      ],
      "metadata": {
        "id": "_FAzm7sDXgCE",
        "outputId": "1a9daa1a-0589-4358-af90-1179f65c060e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'bdd100k'...\n",
            "remote: Enumerating objects: 1761, done.\u001b[K\n",
            "remote: Counting objects: 100% (621/621), done.\u001b[K\n",
            "remote: Compressing objects: 100% (321/321), done.\u001b[K\n",
            "remote: Total 1761 (delta 488), reused 307 (delta 300), pack-reused 1140\u001b[K\n",
            "Receiving objects: 100% (1761/1761), 10.29 MiB | 28.95 MiB/s, done.\n",
            "Resolving deltas: 100% (1087/1087), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd bdd100k"
      ],
      "metadata": {
        "id": "W4tCtO3fpr0_",
        "outputId": "3c930ab7-9add-4e7b-838e-a502d975afca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/bdd100k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "RX_w37rLpvRP",
        "outputId": "0f066584-c708-45b7-d551-a20249a46140",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/scalabel/scalabel.git (from -r requirements.txt (line 23))\n",
            "  Cloning https://github.com/scalabel/scalabel.git to /tmp/pip-req-build-by_8du2m\n",
            "  Running command git clone -q https://github.com/scalabel/scalabel.git /tmp/pip-req-build-by_8du2m\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting black\n",
            "  Downloading black-22.6.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 5.4 MB/s \n",
            "\u001b[?25hCollecting flake8\n",
            "  Downloading flake8-4.0.1-py2.py3-none-any.whl (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 3.2 MB/s \n",
            "\u001b[?25hCollecting flake8-docstrings\n",
            "  Downloading flake8_docstrings-1.6.0-py2.py3-none-any.whl (5.7 kB)\n",
            "Collecting gmplot\n",
            "  Downloading gmplot-1.4.1-py3-none-any.whl (164 kB)\n",
            "\u001b[K     |████████████████████████████████| 164 kB 72.3 MB/s \n",
            "\u001b[?25hCollecting isort\n",
            "  Downloading isort-5.10.1-py3-none-any.whl (103 kB)\n",
            "\u001b[K     |████████████████████████████████| 103 kB 73.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (1.1.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (3.2.2)\n",
            "Collecting motmetrics\n",
            "  Downloading motmetrics-1.2.5-py3-none-any.whl (161 kB)\n",
            "\u001b[K     |████████████████████████████████| 161 kB 74.9 MB/s \n",
            "\u001b[?25hCollecting mypy\n",
            "  Downloading mypy-0.961-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.3 MB 54.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (1.17.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (1.3.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (7.1.2)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (2.0.4)\n",
            "Collecting pylint\n",
            "  Downloading pylint-2.14.4-py3-none-any.whl (488 kB)\n",
            "\u001b[K     |████████████████████████████████| 488 kB 77.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 15)) (3.6.4)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 16)) (0.18.3)\n",
            "Requirement already satisfied: sphinx in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 17)) (1.8.6)\n",
            "Collecting sphinx-rtd-theme\n",
            "  Downloading sphinx_rtd_theme-1.0.0-py2.py3-none-any.whl (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 55.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 19)) (0.8.9)\n",
            "Collecting toml\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 21)) (4.64.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from scalabel==0.3.0->-r requirements.txt (line 23)) (5.4.8)\n",
            "Collecting nanoid\n",
            "  Downloading nanoid-2.0.0-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from scalabel==0.3.0->-r requirements.txt (line 23)) (1.0.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from scalabel==0.3.0->-r requirements.txt (line 23)) (3.13)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from scalabel==0.3.0->-r requirements.txt (line 23)) (3.0.9)\n",
            "Collecting plyfile\n",
            "  Downloading plyfile-0.7.4-py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.7/dist-packages (from scalabel==0.3.0->-r requirements.txt (line 23)) (1.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from scalabel==0.3.0->-r requirements.txt (line 23)) (2.23.0)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.24.22-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 69.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from scalabel==0.3.0->-r requirements.txt (line 23)) (2.8.2)\n",
            "Collecting click>=8.0.0\n",
            "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 685 kB/s \n",
            "\u001b[?25hCollecting platformdirs>=2\n",
            "  Downloading platformdirs-2.5.2-py3-none-any.whl (14 kB)\n",
            "Collecting pathspec>=0.9.0\n",
            "  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting mypy-extensions>=0.4.3\n",
            "  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.7/dist-packages (from black->-r requirements.txt (line 1)) (4.1.1)\n",
            "Collecting typed-ast>=1.4.2\n",
            "  Downloading typed_ast-1.5.4-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (843 kB)\n",
            "\u001b[K     |████████████████████████████████| 843 kB 70.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from black->-r requirements.txt (line 1)) (2.0.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from click>=8.0.0->black->-r requirements.txt (line 1)) (4.11.4)\n",
            "Collecting pyflakes<2.5.0,>=2.4.0\n",
            "  Downloading pyflakes-2.4.0-py2.py3-none-any.whl (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 10.0 MB/s \n",
            "\u001b[?25hCollecting mccabe<0.7.0,>=0.6.0\n",
            "  Downloading mccabe-0.6.1-py2.py3-none-any.whl (8.6 kB)\n",
            "Collecting importlib-metadata\n",
            "  Downloading importlib_metadata-4.2.0-py3-none-any.whl (16 kB)\n",
            "Collecting pycodestyle<2.9.0,>=2.8.0\n",
            "  Downloading pycodestyle-2.8.0-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->click>=8.0.0->black->-r requirements.txt (line 1)) (3.8.0)\n",
            "Collecting pydocstyle>=2.1\n",
            "  Downloading pydocstyle-6.1.1-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: snowballstemmer in /usr/local/lib/python3.7/dist-packages (from pydocstyle>=2.1->flake8-docstrings->-r requirements.txt (line 3)) (2.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 7)) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 7)) (1.4.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->scalabel==0.3.0->-r requirements.txt (line 23)) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from motmetrics->-r requirements.txt (line 8)) (1.4.1)\n",
            "Collecting xmltodict>=0.12.0\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Collecting numpy\n",
            "  Downloading numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 45.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 11)) (2022.1)\n",
            "Collecting tomlkit>=0.10.1\n",
            "  Downloading tomlkit-0.11.0-py3-none-any.whl (34 kB)\n",
            "Collecting astroid<=2.12.0-dev0,>=2.11.6\n",
            "  Downloading astroid-2.11.6-py3-none-any.whl (251 kB)\n",
            "\u001b[K     |████████████████████████████████| 251 kB 75.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill>=0.2 in /usr/local/lib/python3.7/dist-packages (from pylint->-r requirements.txt (line 14)) (0.3.5.1)\n",
            "Requirement already satisfied: wrapt<2,>=1.11 in /usr/local/lib/python3.7/dist-packages (from astroid<=2.12.0-dev0,>=2.11.6->pylint->-r requirements.txt (line 14)) (1.14.1)\n",
            "Requirement already satisfied: setuptools>=20.0 in /usr/local/lib/python3.7/dist-packages (from astroid<=2.12.0-dev0,>=2.11.6->pylint->-r requirements.txt (line 14)) (57.4.0)\n",
            "Collecting lazy-object-proxy>=1.4.0\n",
            "  Downloading lazy_object_proxy-1.7.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 6.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->-r requirements.txt (line 15)) (21.4.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->-r requirements.txt (line 15)) (8.13.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->-r requirements.txt (line 15)) (1.11.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->-r requirements.txt (line 15)) (0.7.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->-r requirements.txt (line 15)) (1.4.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 16)) (2.6.3)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 16)) (2.4.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 16)) (2021.11.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 16)) (1.3.0)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.7/dist-packages (from sphinx->-r requirements.txt (line 17)) (2.11.3)\n",
            "Requirement already satisfied: docutils<0.18,>=0.11 in /usr/local/lib/python3.7/dist-packages (from sphinx->-r requirements.txt (line 17)) (0.17.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from sphinx->-r requirements.txt (line 17)) (0.7.12)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.7/dist-packages (from sphinx->-r requirements.txt (line 17)) (1.2.4)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.7/dist-packages (from sphinx->-r requirements.txt (line 17)) (2.6.1)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from sphinx->-r requirements.txt (line 17)) (1.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from sphinx->-r requirements.txt (line 17)) (21.3)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.7/dist-packages (from sphinx->-r requirements.txt (line 17)) (2.10.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.3->sphinx->-r requirements.txt (line 17)) (2.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->scalabel==0.3.0->-r requirements.txt (line 23)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->scalabel==0.3.0->-r requirements.txt (line 23)) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->scalabel==0.3.0->-r requirements.txt (line 23)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->scalabel==0.3.0->-r requirements.txt (line 23)) (1.24.3)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 10.8 MB/s \n",
            "\u001b[?25hCollecting botocore<1.28.0,>=1.27.22\n",
            "  Downloading botocore-1.27.22-py3-none-any.whl (8.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.9 MB 57.9 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 73.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->scalabel==0.3.0->-r requirements.txt (line 23)) (3.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.7/dist-packages (from sphinxcontrib-websupport->sphinx->-r requirements.txt (line 17)) (1.1.5)\n",
            "Building wheels for collected packages: scalabel\n",
            "  Building wheel for scalabel (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scalabel: filename=scalabel-0.3.0-py3-none-any.whl size=12093361 sha256=429f69249240cb257fa712f0702487dbf9555f151207336c7df93b427cc87a06\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-hfudyaik/wheels/d0/db/51/8d89f1d79d9aa40ca18a2bacfa889dd76b53ccf7cbae0390cb\n",
            "Successfully built scalabel\n",
            "Installing collected packages: urllib3, jmespath, numpy, botocore, xmltodict, typed-ast, s3transfer, pyflakes, pycodestyle, mccabe, lazy-object-proxy, importlib-metadata, tomlkit, toml, pydocstyle, plyfile, platformdirs, pathspec, nanoid, mypy-extensions, motmetrics, isort, flake8, click, boto3, astroid, sphinx-rtd-theme, scalabel, pylint, mypy, gmplot, flake8-docstrings, black\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.17.0\n",
            "    Uninstalling numpy-1.17.0:\n",
            "      Successfully uninstalled numpy-1.17.0\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.11.4\n",
            "    Uninstalling importlib-metadata-4.11.4:\n",
            "      Successfully uninstalled importlib-metadata-4.11.4\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 7.1.2\n",
            "    Uninstalling click-7.1.2:\n",
            "      Successfully uninstalled click-7.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.6.0 which is incompatible.\n",
            "markdown 3.3.7 requires importlib-metadata>=4.4; python_version < \"3.10\", but you have importlib-metadata 4.2.0 which is incompatible.\n",
            "flask 1.1.4 requires click<8.0,>=5.1, but you have click 8.1.3 which is incompatible.\n",
            "fastai 2.6.3 requires torch<1.12,>=1.7.0, but you have torch 1.6.0 which is incompatible.\n",
            "fastai 2.6.3 requires torchvision>=0.8.2, but you have torchvision 0.7.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed astroid-2.11.6 black-22.6.0 boto3-1.24.22 botocore-1.27.22 click-8.1.3 flake8-4.0.1 flake8-docstrings-1.6.0 gmplot-1.4.1 importlib-metadata-4.2.0 isort-5.10.1 jmespath-1.0.1 lazy-object-proxy-1.7.1 mccabe-0.6.1 motmetrics-1.2.5 mypy-0.961 mypy-extensions-0.4.3 nanoid-2.0.0 numpy-1.21.6 pathspec-0.9.0 platformdirs-2.5.2 plyfile-0.7.4 pycodestyle-2.8.0 pydocstyle-6.1.1 pyflakes-2.4.0 pylint-2.14.4 s3transfer-0.6.0 scalabel-0.3.0 sphinx-rtd-theme-1.0.0 toml-0.10.2 tomlkit-0.11.0 typed-ast-1.5.4 urllib3-1.25.11 xmltodict-0.13.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3xJGjocOQv8",
        "outputId": "ee4a563d-9217-4bd8-dcbf-5f617136110b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/.shortcut-targets-by-id/16kphvlmJsL1izzffpLfadthz0YrraYkW/ImageIdetificationProject/Project_work/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHJPzwSCORqx",
        "outputId": "502ec8c0-31b0-47ac-e43f-acece59b8244"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/16kphvlmJsL1izzffpLfadthz0YrraYkW/ImageIdetificationProject/Project_work\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir labels/valids/\n",
        "!mkdir labels/trains/"
      ],
      "metadata": {
        "id": "2HcWuvp0Oqzm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import argparse\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "\n",
        "def bdd2coco_detection(id_dict, labeled_images, fn):\n",
        "\n",
        "    images = list()\n",
        "    annotations = list()\n",
        "\n",
        "    counter = 0\n",
        "    for i in tqdm(labeled_images):\n",
        "        counter += 1\n",
        "        image = dict()\n",
        "        if('labels' in i.keys()):\n",
        "          image['file_name'] = i['name']\n",
        "          image['height'] = 720\n",
        "          image['width'] = 1280\n",
        "\n",
        "          image['id'] = counter\n",
        "\n",
        "          empty_image = True\n",
        "\n",
        "          for label in i['labels']:\n",
        "              annotation = dict()\n",
        "              category=label['category']\n",
        "              if (category == \"traffic light\"):\n",
        "                  color = label['attributes']['trafficLightColor']\n",
        "                  category = \"tl_\" + color\n",
        "              if category in id_dict.keys():\n",
        "                  empty_image = False\n",
        "                  annotation[\"iscrowd\"] = 0\n",
        "                  annotation[\"image_id\"] = image['id']\n",
        "                  x1 = label['box2d']['x1']\n",
        "                  y1 = label['box2d']['y1']\n",
        "                  x2 = label['box2d']['x2']\n",
        "                  y2 = label['box2d']['y2']\n",
        "                  annotation['bbox'] = [x1, y1, x2-x1, y2-y1]\n",
        "                  annotation['area'] = float((x2 - x1) * (y2 - y1))\n",
        "                  annotation['category_id'] = id_dict[category]\n",
        "                  annotation['ignore'] = 0\n",
        "                  annotation['id'] = label['id']\n",
        "                  annotation['segmentation'] = [[x1, y1, x1, y2, x2, y2, x2, y1]]\n",
        "                  annotations.append(annotation)\n",
        "\n",
        "          if empty_image:\n",
        "              continue\n",
        "\n",
        "          images.append(image)\n",
        "\n",
        "    attr_dict[\"images\"] = images\n",
        "    attr_dict[\"annotations\"] = annotations\n",
        "    attr_dict[\"type\"] = \"instances\"\n",
        "\n",
        "    print('saving...')\n",
        "    json_string = json.dumps(attr_dict)\n",
        "    with open(fn, \"w\") as file:\n",
        "        file.write(json_string)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    label_dir=\"/content/drive/.shortcut-targets-by-id/16kphvlmJsL1izzffpLfadthz0YrraYkW/ImageIdetificationProject/Project_work/bdd100k/labels/\"\n",
        "    save_path=\"/content/drive/.shortcut-targets-by-id/16kphvlmJsL1izzffpLfadthz0YrraYkW/ImageIdetificationProject/Project_work/labels/\"\n",
        "\n",
        "    attr_dict = dict()\n",
        "    attr_dict[\"categories\"] = [\n",
        "        {\"supercategory\": \"none\", \"id\": 1, \"name\": \"person\"},\n",
        "        {\"supercategory\": \"none\", \"id\": 2, \"name\": \"rider\"},\n",
        "        {\"supercategory\": \"none\", \"id\": 3, \"name\": \"car\"},\n",
        "        {\"supercategory\": \"none\", \"id\": 4, \"name\": \"bus\"},\n",
        "        {\"supercategory\": \"none\", \"id\": 5, \"name\": \"truck\"},\n",
        "        {\"supercategory\": \"none\", \"id\": 6, \"name\": \"bike\"},\n",
        "        {\"supercategory\": \"none\", \"id\": 7, \"name\": \"motor\"},\n",
        "        {\"supercategory\": \"none\", \"id\": 8, \"name\": \"tl_green\"},\n",
        "        {\"supercategory\": \"none\", \"id\": 9, \"name\": \"tl_red\"},\n",
        "        {\"supercategory\": \"none\", \"id\": 10, \"name\": \"tl_yellow\"},\n",
        "        {\"supercategory\": \"none\", \"id\": 11, \"name\": \"tl_none\"},\n",
        "        {\"supercategory\": \"none\", \"id\": 12, \"name\": \"traffic sign\"},\n",
        "        {\"supercategory\": \"none\", \"id\": 13, \"name\": \"train\"}\n",
        "    ]\n",
        "\n",
        "    attr_id_dict = {i['name']: i['id'] for i in attr_dict['categories']}\n",
        "\n",
        "    # create BDD training set detections in COCO format\n",
        "    print('Loading training set...')\n",
        "    with open(os.path.join(label_dir,\n",
        "                           'det_train.json')) as f:\n",
        "        train_labels = json.load(f)\n",
        "    print('Converting training set...')\n",
        "\n",
        "    out_fn = os.path.join(save_path,\n",
        "                          'bdd100k_labels_images_det_coco_train.json')\n",
        "    bdd2coco_detection(attr_id_dict, train_labels, out_fn)\n",
        "\n",
        "    print('Loading validation set...')\n",
        "    # create BDD validation set detections in COCO format\n",
        "    with open(os.path.join(label_dir,\n",
        "                           'det_val.json')) as f:\n",
        "        val_labels = json.load(f)\n",
        "    print('Converting validation set...')\n",
        "\n",
        "    out_fn = os.path.join(save_path,\n",
        "                          'bdd100k_labels_images_det_coco_val.json')\n",
        "    bdd2coco_detection(attr_id_dict, val_labels, out_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEUaM1I_O-x5",
        "outputId": "53f2360e-d4d7-4955-e075-67c8232445fc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading training set...\n",
            "Converting training set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69863/69863 [00:08<00:00, 8156.74it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saving...\n",
            "Loading validation set...\n",
            "Converting validation set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [00:00<00:00, 21325.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saving...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = json.load(open('/content/drive/.shortcut-targets-by-id/16kphvlmJsL1izzffpLfadthz0YrraYkW/ImageIdetificationProject/Project_work/labels/bdd100k_labels_images_det_coco_train.json'))"
      ],
      "metadata": {
        "id": "Fn99n_6LnvHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import json\n",
        "import pandas as pd\n",
        "class ConvertCOCOToYOLO:\n",
        "\n",
        "    \"\"\"\n",
        "    Takes in the path to COCO annotations and outputs YOLO annotations in multiple .txt files.\n",
        "    COCO annotation are to be JSON formart as follows:\n",
        "        \"annotations\":{\n",
        "            \"area\":2304645,\n",
        "            \"id\":1,\n",
        "            \"image_id\":10,\n",
        "            \"category_id\":4,\n",
        "            \"bbox\":[\n",
        "                0::704\n",
        "                1:620\n",
        "                2:1401\n",
        "                3:1645\n",
        "            ]\n",
        "        }\n",
        "        \n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, img_folder, json_path):\n",
        "        self.img_folder = img_folder\n",
        "        self.json_path = json_path\n",
        "        \n",
        "\n",
        "    def get_img_shape(self, img_path):\n",
        "        img = cv2.imread(img_path)\n",
        "        try:\n",
        "            return img.shape\n",
        "        except AttributeError:\n",
        "            print('error!', img_path)\n",
        "            return (None, None, None)\n",
        "\n",
        "    def convert_labels(self, img_attr, x1, y1, x2, y2):\n",
        "        \"\"\"\n",
        "        Definition: Parses label files to extract label and bounding box\n",
        "        coordinates. Converts (x1, y1, x1, y2) KITTI format to\n",
        "        (x, y, width, height) normalized YOLO format.\n",
        "        \"\"\"\n",
        "\n",
        "        def sorting(l1, l2):\n",
        "            if l1 > l2:\n",
        "                lmax, lmin = l1, l2\n",
        "                return lmax, lmin\n",
        "            else:\n",
        "                lmax, lmin = l2, l1\n",
        "                return lmax, lmin\n",
        "\n",
        "        # size = self.get_img_shape(img_path)\n",
        "        xmax, xmin = sorting(x1, x2)\n",
        "        ymax, ymin = sorting(y1, y2)\n",
        "        dw = 1./img_attr['width']\n",
        "        dh = 1./img_attr['height']\n",
        "        x = (xmin + xmax)/2.0\n",
        "        y = (ymin + ymax)/2.0\n",
        "        w = xmax - xmin\n",
        "        h = ymax - ymin\n",
        "        x = x*dw\n",
        "        w = w*dw\n",
        "        y = y*dh\n",
        "        h = h*dh\n",
        "        return (x,y,w,h)\n",
        "\n",
        "    def convert(self,annotation_key='annotations',img_id='image_id',cat_id='category_id',bbox_id='bbox'):\n",
        "        # Enter directory to read JSON file\n",
        "        data = self.json_path\n",
        "        annotations = pd.DataFrame.from_dict(data[annotation_key])\n",
        "        images = pd.DataFrame.from_dict(data[img_id])\n",
        "        images.set_index('id',inplace=True)\n",
        "        check_set = set()\n",
        "\n",
        "        # Retrieve data\n",
        "        for i in range(annotations.last_valid_index()):\n",
        "            \n",
        "            # # Get required data\n",
        "            image_attributes = annotations.iloc[i]['image_id']\n",
        "            # if(image_attributes>3):\n",
        "            #   break\n",
        "            image_attributes = images.iloc[image_attributes]\n",
        "            # print(image_id)\n",
        "            category_id = annotations.iloc[i]['category_id']\n",
        "            # print(category_id)\n",
        "            bbox = annotations.iloc[i][bbox_id]\n",
        "            # print(bbox)\n",
        "\n",
        "\n",
        "            # # Convert the data\n",
        "            kitti_bbox = [bbox[0], bbox[1], bbox[2] + bbox[0], bbox[3] + bbox[1]]\n",
        "            # print(kitti_bbox)\n",
        "            # print(image_attributes)\n",
        "            yolo_bbox = self.convert_labels(image_attributes, kitti_bbox[0], kitti_bbox[1], kitti_bbox[2], kitti_bbox[3])\n",
        "            # print(yolo_bbox)\n",
        "            \n",
        "            # # Prepare for export\n",
        "            image_id = image_attributes['file_name'].split('.')[0]\n",
        "            print(f'writing {image_id}')\n",
        "            filename = f'/content/drive/.shortcut-targets-by-id/16kphvlmJsL1izzffpLfadthz0YrraYkW/ImageIdetificationProject/Project_work/labels/trains/{image_id}.txt'\n",
        "            content =f\"{category_id} {yolo_bbox[0]} {yolo_bbox[1]} {yolo_bbox[2]} {yolo_bbox[3]}\"\n",
        "\n",
        "            # # Export \n",
        "            if image_id in check_set:\n",
        "                # Append to existing file as there can be more than one label in each image\n",
        "                file = open(filename, \"a\")\n",
        "                file.write(\"\\n\")\n",
        "                file.write(content)\n",
        "                file.close()\n",
        "\n",
        "            elif image_id not in check_set:\n",
        "                check_set.add(image_id)\n",
        "                # Write files\n",
        "                file = open(filename, \"w\")\n",
        "                file.write(content)\n",
        "                file.close()\n",
        "            \n",
        "\n",
        "\n",
        "# To run in as a class\n"
      ],
      "metadata": {
        "id": "lwXnKgoQoXti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    ConvertCOCOToYOLO(img_folder='/content/drive/.shortcut-targets-by-id/16kphvlmJsL1izzffpLfadthz0YrraYkW/ImageIdetificationProject/Project_work/images/100k/train',json_path=data).convert(img_id='images')"
      ],
      "metadata": {
        "id": "8EVGnuExr8md"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZnAhTNsYeWsz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}